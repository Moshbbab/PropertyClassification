{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "import os\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from config import pathDict\n",
    "from conv_net.train import Train\n",
    "from conv_net.test import Test\n",
    "from data_transformation.data_prep import get_valid_land_house_ids, dumpStratifiedBatches_balanced_class\n",
    "from plot import Plot\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "images_per_label = None # normally 5000 each label is good\n",
    "assessor_img_type = 'assessor'\n",
    "aerial_img_type = 'google_aerial' # 'bing_aerial'\n",
    "overlayed_img_type = 'google_overlayed'\n",
    "streetside_img_type = None\n",
    "\n",
    "\n",
    "image_type = overlayed_img_type\n",
    "\n",
    "if image_type == 'assessor':\n",
    "    inp_image_shape = [260, 260, 3]\n",
    "elif image_type == 'google_aerial':\n",
    "    inp_image_shape = [400, 400, 3]\n",
    "elif image_type == 'google_overlayed':\n",
    "    inp_image_shape = [400, 400, 3]\n",
    "elif image_type == 'google_streetside':\n",
    "    inp_image_shape = [260, 260, 3]\n",
    "else:\n",
    "    raise ValueError('Not a valid image type provided')\n",
    "    \n",
    "which_net = 'convnet'\n",
    "batch_prepare = True\n",
    "train = True\n",
    "test = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARE/DUMP BATCHES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\newline\\Documents\\ImageClassification\\data\\input_images\\aerial_images\\google\\land\n",
      "aerial pins:  5433 5433\n",
      "common aerial pins:  5433 5433\n",
      "C:\\Users\\newline\\Documents\\ImageClassification\\data\\input_images\\overlayed_images\\google\\land\n",
      "overlayed pins:  5433 5433\n",
      "common overlayed pins:  5433 5433\n",
      "5433 5433\n",
      "--------------- 237.3948187828064 seconds ------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cmn_land_pins, cmn_house_pins = get_valid_land_house_ids(\n",
    "        aerial_img_type=aerial_img_type,\n",
    "        streetside_img_type=streetside_img_type,\n",
    "        overlayed_img_type=overlayed_img_type,\n",
    "        images_per_label=images_per_label)\n",
    "print (len(cmn_land_pins), len(cmn_house_pins))\n",
    "\n",
    "\n",
    "\n",
    "tr_batch_size = 128\n",
    "max_batches = 3\n",
    "ts_batch_size = (len(cmn_land_pins) + len(cmn_house_pins)) // 10\n",
    "cv_batch_size = (len(cmn_land_pins) + len(cmn_house_pins)) // 10\n",
    "\n",
    "dumpStratifiedBatches_balanced_class(cmn_land_pins, cmn_house_pins, img_resize_shape=inp_image_shape,\n",
    "                                     image_type=image_type, ts_batch_size=ts_batch_size, \n",
    "                                     cv_batch_size=cv_batch_size, tr_batch_size=tr_batch_size,\n",
    "                                     shuffle_seed=873, get_stats=True, max_batches=max_batches)\n",
    "\n",
    "print ('--------------- %s seconds ------------------'%(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATE MODELS:\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN MODEL: Overlayed Images [Central crop: 96 x 96]\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train  learning_rate = 0.0001\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping Checkpoints to %s C:\\Users\\newline\\Documents\\ImageClassification\\data\\data_models\\overlayed_images\\google\\checkpoint\\convnet\n",
      "Dumping Tensorboard Summary to %s C:\\Users\\newline\\Documents\\ImageClassification\\data\\data_models\\overlayed_images\\google\\summary\\convnet\n",
      "Learning Rate: Initial:  0.0005\n",
      "Checkpoint latest at:  C:\\Users\\newline\\Documents\\ImageClassification\\data\\data_models\\overlayed_images\\google\\checkpoint\\convnet\\convnet_epoch_2_batch_2\n",
      "----------41.95160913467407 seconds------------\n"
     ]
    }
   ],
   "source": [
    "max_batches = 3\n",
    "start_time = time.time()\n",
    "if train:\n",
    "    tr_obj = Train(dict(inp_img_shape=[400, 400, 3],\n",
    "                        crop_shape=[96, 96, 3],\n",
    "                        out_img_shape=[96, 96, 3],\n",
    "                        use_checkpoint=True,\n",
    "                        save_checkpoint=True,\n",
    "                        write_tensorboard_summary=False\n",
    "                        ),\n",
    "                   device_type='gpu',\n",
    "                   which_net='convnet',  # vgg\n",
    "                   image_type='google_overlayed')\n",
    "    (tr_loss_arr, tr_acc_arr, tr_precision_arr, tr_recall_arr,\n",
    "     cv_loss_arr, cv_acc_arr, cv_precision_arr, cv_recall_arr,\n",
    "     l_rate_arr) = tr_obj.run(num_epochs=3, num_batches=max_batches, get_stats_at=10)  # + 1)\n",
    "    \n",
    "print('----------%s seconds------------'%(str(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dumping Checkpoints to %s C:\\Users\\newline\\Documents\\ImageClassification\\data\\data_models\\overlayed_images\\google\\checkpoint\\convnet\n",
      "Dumping Tensorboard Summary to %s C:\\Users\\newline\\Documents\\ImageClassification\\data\\data_models\\overlayed_images\\google\\summary\\convnet\n",
      "Learning Rate: Initial:  0.0005\n",
      "Checkpoint latest at:  C:\\Users\\newline\\Documents\\ImageClassification\\data\\data_models\\overlayed_images\\google\\checkpoint\\convnet\\convnet_epoch_5_batch_2\n"
     ]
    }
   ],
   "source": [
    "max_batches = 3\n",
    "start_time = time.time()\n",
    "if train:\n",
    "    tr_obj = Train(dict(inp_img_shape=[400, 400, 3],\n",
    "                        crop_shape=[96, 96, 3],\n",
    "                        out_img_shape=[96, 96, 3],\n",
    "                        use_checkpoint=True,\n",
    "                        save_checkpoint=True,\n",
    "                        write_tensorboard_summary=False\n",
    "                        ),\n",
    "                   device_type='cpu',\n",
    "                   which_net='convnet',  # vgg\n",
    "                   image_type='google_overlayed')\n",
    "    (tr_loss_arr, tr_acc_arr, tr_precision_arr, tr_recall_arr,\n",
    "     cv_loss_arr, cv_acc_arr, cv_precision_arr, cv_recall_arr,\n",
    "     l_rate_arr) = tr_obj.run(num_epochs=3, num_batches=max_batches, get_stats_at=10)  # + 1)\n",
    "    \n",
    "print('----------%s seconds------------'%(str(time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

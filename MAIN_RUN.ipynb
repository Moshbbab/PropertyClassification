{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hmm.. Lets Ben:\n",
    "\n",
    "As an user you are suppose to modify just the first cell. and run the entire notebook. Don't worry about repeating task or subtasks during network problems and any other failures. The code is written in a way to not repeat task when failure occurs and you want to initiate the code form the failed point.\n",
    "\n",
    "* input_csv_path: Is your path to csv file with property address. Note this file has a specific format. If the format is not met then the cleaning process would through an error.\n",
    "* which_run: This can be any name but should be unique to previous run. If not unique then it will overwrite the output of any previous run with the same name. (example: 'may_31_2018'). This is improtant becasue you can find all the relevant statistics for your run int subfolder creates with the provided name.\n",
    "* image_type: Represents the image type you would like to run.\n",
    "* filter_conditions: This parameter may look weird, but we have it in this way to sync it with the apache Airflow variable declaration. You just have to change the third value after the \":\".\n",
    "\n",
    "and so on ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from jobs.data_load import dump_aerial, dump_aerial_cropped, dump_overlaid, create_csv_file_for_input\n",
    "from jobs.batch_create import prepare_batches, remove_batches\n",
    "from jobs.train_cv_test import test_new, predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_csv_path = '/Users/sam/All-Program/App-DataSet/HouseClassification/house_metadata_nw.csv'\n",
    "which_run = 'new_test'\n",
    "image_type = 'aerial_cropped'\n",
    "use_checkpoint_of_run = 'sam_new'\n",
    "prediction_threshold = 0.68\n",
    "filter_conditions = 'last_reviewed_ts : bool : True \\n\\\n",
    "from_year : int : 2015 \\n\\\n",
    "to_year : int : 2016 \\n\\\n",
    "from_month : int : 6 \\n\\\n",
    "to_month : int : 7 \\n\\\n",
    "which_city : str : chicago \\n\\\n",
    "use_improvement_lvl : bool : True \\n\\\n",
    "max_num_records : int : 264'\n",
    "\n",
    "which_net = 'resnet'\n",
    "batch_size = 128\n",
    "proportion_cv_data = 0.05\n",
    "proportion_test_data = 0.05\n",
    "\n",
    "# print(filter_conditions)  \n",
    "# print ('')\n",
    "# Parse Variables\n",
    "cond_dict = {}\n",
    "filter_conditions = filter_conditions.split('\\n')\n",
    "# print (filter_conditions)\n",
    "for conds in filter_conditions:\n",
    "#     print (conds,'\\n')\n",
    "    k, func, v = conds.split(':')\n",
    "#     print (k, func, v)\n",
    "    if func.strip() == 'None':\n",
    "        cond_dict[k.strip()] = None\n",
    "    elif func.strip() == 'bool':\n",
    "        cond_dict[k.strip()] = bool(v.strip())\n",
    "    elif func.strip() == 'int':\n",
    "        cond_dict[k.strip()] = int(v.strip())\n",
    "    elif func.strip() == 'float':\n",
    "        cond_dict[k.strip()] = float(v.strip())\n",
    "    elif func.strip() == 'str':\n",
    "        cond_dict[k.strip()] = str(v.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from_month': 6,\n",
       " 'from_year': 2015,\n",
       " 'last_reviewed_ts': True,\n",
       " 'max_num_records': 264,\n",
       " 'to_month': 7,\n",
       " 'to_year': 2016,\n",
       " 'use_improvement_lvl': True,\n",
       " 'which_city': 'chicago'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN RECORDS FROM THE CSV FILE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/App-Setup/anaconda/envs/anaconda35/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2862: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: Metadata table (220364, 18)\n",
      "Data shape  = (220364, 18)\n",
      "Applying conditions: from_year 2015 - to_year 2015\n",
      "Data shape  = (21683, 18)\n",
      "Applying conditions: from_month 6 - to_month 6\n",
      "Data shape  = (11175, 18)\n",
      "Applying conditions: city: chicago\n",
      "Data shape  = (9267, 18)\n",
      "Applying conditions: improvement_lvl: True\n",
      "Data shape land = (4265, 18), house = (4897, 18)\n",
      "Applying conditions: max_num_records: 264\n",
      "Shape: Land Property table (132, 18)\n",
      "Shape: House Property table (132, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'COMPLETE'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = dict(\n",
    "          input_csv_path=input_csv_path,\n",
    "          which_run=which_run,\n",
    "          img_type= image_type,\n",
    "          cond_dict=cond_dict\n",
    ")\n",
    "\n",
    "create_csv_file_for_input(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FETCH AERIAL IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COMPLETE'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict=dict(\n",
    "      which_run=which_run,\n",
    "      img_type= image_type\n",
    ")\n",
    "\n",
    "dump_aerial(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUMP AERIAL CROPPED IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating Run for scoop scoop_738_768 : DATA SHAPE (93246, 13)\n",
      "Total images to be processed are  (32, 9)\n",
      "Initiating Run for scoop scoop_768_798 : DATA SHAPE (94331, 13)\n",
      "Total images to be processed are  (28, 9)\n",
      "Initiating Run for scoop scoop_798_848 : DATA SHAPE (80697, 13)\n",
      "Total images to be processed are  (19, 9)\n",
      "Initiating Run for scoop scoop_848_908 : DATA SHAPE (90177, 13)\n",
      "Total images to be processed are  (28, 9)\n",
      "Initiating Run for scoop scoop_908_938 : DATA SHAPE (92080, 13)\n",
      "Total images to be processed are  (6, 9)\n",
      "Initiating Run for scoop scoop_938_968 : DATA SHAPE (91240, 13)\n",
      "Total images to be processed are  (3, 9)\n",
      "Initiating Run for scoop scoop_968_028 : DATA SHAPE (86448, 13)\n",
      "Total images to be processed are  (8, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'COMPLETE'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict=dict(\n",
    "      which_run=which_run,\n",
    "      img_type= image_type\n",
    ")\n",
    "\n",
    "if image_type == 'aerial_cropped':\n",
    "    dump_aerial_cropped(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUMP OVERLAID IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dict=dict(\n",
    "      which_run=which_run,\n",
    "      img_type= image_type\n",
    ")\n",
    "\n",
    "if image_type == 'overlaid':\n",
    "    dump_overlaid(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST ON NEW IMAGES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Graphs: RESNET\n",
      "Learning Rate: Initial:  0.0005\n",
      "INFO:tensorflow:Restoring parameters from /Users/sam/All-Program/App-DataSet/HouseClassification/checkpoints/sam_new/aerial_cropped/resnet/resnet_epoch_29_batch_89\n",
      "Batch path /Users/sam/All-Program/App-DataSet/HouseClassification/batch_data/new_test/aerial_cropped, batch_names: ['batch_17', 'batch_6', 'batch_13', 'batch_2', 'batch_12', 'batch_3', 'batch_16', 'batch_7', 'batch_8', 'batch_9', 'batch_11', 'batch_0', 'batch_15', 'batch_4', 'batch_14', 'batch_5', 'batch_10', 'batch_1']\n",
      "Test Graphs: RESNET\n",
      "Learning Rate: Initial:  0.0005\n",
      "INFO:tensorflow:Restoring parameters from /Users/sam/All-Program/App-DataSet/HouseClassification/checkpoints/sam_new/aerial_cropped/resnet/resnet_epoch_29_batch_99\n",
      "Batch path /Users/sam/All-Program/App-DataSet/HouseClassification/batch_data/new_test/aerial_cropped, batch_names: ['batch_17', 'batch_6', 'batch_13', 'batch_2', 'batch_12', 'batch_3', 'batch_16', 'batch_7', 'batch_8', 'batch_9', 'batch_11', 'batch_0', 'batch_15', 'batch_4', 'batch_14', 'batch_5', 'batch_10', 'batch_1']\n",
      "Test Graphs: RESNET\n",
      "Learning Rate: Initial:  0.0005\n",
      "INFO:tensorflow:Restoring parameters from /Users/sam/All-Program/App-DataSet/HouseClassification/checkpoints/sam_new/aerial_cropped/resnet/resnet_epoch_29_batch_109\n",
      "Batch path /Users/sam/All-Program/App-DataSet/HouseClassification/batch_data/new_test/aerial_cropped, batch_names: ['batch_17', 'batch_6', 'batch_13', 'batch_2', 'batch_12', 'batch_3', 'batch_16', 'batch_7', 'batch_8', 'batch_9', 'batch_11', 'batch_0', 'batch_15', 'batch_4', 'batch_14', 'batch_5', 'batch_10', 'batch_1']\n",
      "Test Graphs: RESNET\n",
      "Learning Rate: Initial:  0.0005\n",
      "INFO:tensorflow:Restoring parameters from /Users/sam/All-Program/App-DataSet/HouseClassification/checkpoints/sam_new/aerial_cropped/resnet/resnet_epoch_29_batch_116\n",
      "Batch path /Users/sam/All-Program/App-DataSet/HouseClassification/batch_data/new_test/aerial_cropped, batch_names: ['batch_17', 'batch_6', 'batch_13', 'batch_2', 'batch_12', 'batch_3', 'batch_16', 'batch_7', 'batch_8', 'batch_9', 'batch_11', 'batch_0', 'batch_15', 'batch_4', 'batch_14', 'batch_5', 'batch_10', 'batch_1']\n",
      "Test Graphs: RESNET\n",
      "Learning Rate: Initial:  0.0005\n",
      "INFO:tensorflow:Restoring parameters from /Users/sam/All-Program/App-DataSet/HouseClassification/checkpoints/sam_new/aerial_cropped/resnet/resnet_epoch_30_batch_9\n",
      "Batch path /Users/sam/All-Program/App-DataSet/HouseClassification/batch_data/new_test/aerial_cropped, batch_names: ['batch_17', 'batch_6', 'batch_13', 'batch_2', 'batch_12', 'batch_3', 'batch_16', 'batch_7', 'batch_8', 'batch_9', 'batch_11', 'batch_0', 'batch_15', 'batch_4', 'batch_14', 'batch_5', 'batch_10', 'batch_1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'COMPLETE'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = dict(\n",
    "      which_run=which_run,\n",
    "      img_type=image_type,\n",
    "      use_checkpoint_for_run=use_checkpoint_of_run,\n",
    "      use_checkpoint_for_imageType=image_type,\n",
    "      which_net=which_net\n",
    ")\n",
    "\n",
    "test_new(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAKE FINAL PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint LISTS .. %s ['resnet_epoch_30_batch_9', 'resnet_epoch_29_batch_89', 'resnet_epoch_29_batch_116', 'resnet_epoch_29_batch_99', 'resnet_epoch_29_batch_109']\n",
      "pred_stats.shape = (11870, 6), meta_stats.shape = (2374, 5)\n",
      "The accuracy using predictions from multiple checkpoint is:  0.887952822241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'COMPLETE'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = dict(\n",
    "        which_run=which_run,\n",
    "        img_type=image_type,\n",
    "        use_checkpoint_for_run=use_checkpoint_of_run,\n",
    "        use_checkpoint_for_imageType=image_type,\n",
    "        which_net=which_net,\n",
    "        use_checkpoint_for_prediction='all',\n",
    "        classification_threshold=prediction_threshold\n",
    ")\n",
    "\n",
    "predictions(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "        which_run=which_run,\n",
    "        img_type=image_type\n",
    ")\n",
    "\n",
    "remove_batches(params=param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

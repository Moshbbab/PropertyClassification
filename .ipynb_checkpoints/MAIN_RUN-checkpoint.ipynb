{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hmm.. Lets Begin the Prediction:\n",
    "\n",
    "As an user you are suppose to modify just the first cell. and run the entire notebook. Don't worry about repeating task or subtasks during network problems and any other failures. The code is written in a way to not repeat task when failure occurs and you want to initiate the code form the failed point.\n",
    "\n",
    "* input_csv_path: Is your path to csv file with property address. Note this file has a specific format. If the format is not met then the cleaning process would through an error.\n",
    "* which_run: This can be any name but should be unique to previous run. If not unique then it will overwrite the output of any previous run with the same name. (example: 'may_31_2018'). This is improtant becasue you can find all the relevant statistics for your run int subfolder creates with the provided name.\n",
    "* image_type: Represents the image type you would like to run.\n",
    "* filter_conditions: This parameter may look weird, but we have it in this way to sync it with the apache Airflow variable declaration. You just have to change the third value after the \":\".\n",
    "\n",
    "and so on ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from jobs.data_load import dump_aerial, dump_aerial_cropped, dump_overlaid, create_csv_file_for_input\n",
    "from jobs.batch_create import prepare_batches, remove_batches\n",
    "from jobs.train_cv_test import test_new, predictions\n",
    "\n",
    "\n",
    "# These are the parameters you need to change\n",
    "\n",
    "input_csv_path = r'C:\\Users\\newline\\Documents\\ImageClassification\\data\\house_metadata_nw.csv'\n",
    "which_run = 'session_new'\n",
    "image_type = 'aerial_cropped'\n",
    "use_checkpoint_of_run = 'sam_new'\n",
    "prediction_threshold = 0.68\n",
    "filter_conditions = 'last_reviewed_ts : bool : True \\n\\\n",
    "from_year : int : 2015 \\n\\\n",
    "to_year : int : 2016 \\n\\\n",
    "from_month : int : 6 \\n\\\n",
    "to_month : int : 7 \\n\\\n",
    "which_city : str : chicago \\n\\\n",
    "use_improvement_lvl : bool : True \\n\\\n",
    "max_num_records : int : 264'\n",
    "\n",
    "which_net = 'resnet'\n",
    "batch_size = 128\n",
    "proportion_cv_data = 0.05\n",
    "proportion_test_data = 0.05\n",
    "\n",
    "# print(filter_conditions)  \n",
    "# print ('')\n",
    "# Parse Variables\n",
    "cond_dict = {}\n",
    "filter_conditions = filter_conditions.split('\\n')\n",
    "# print (filter_conditions)\n",
    "for conds in filter_conditions:\n",
    "#     print (conds,'\\n')\n",
    "    k, func, v = conds.split(':')\n",
    "#     print (k, func, v)\n",
    "    if func.strip() == 'None':\n",
    "        cond_dict[k.strip()] = None\n",
    "    elif func.strip() == 'bool':\n",
    "        cond_dict[k.strip()] = bool(v.strip())\n",
    "    elif func.strip() == 'int':\n",
    "        cond_dict[k.strip()] = int(v.strip())\n",
    "    elif func.strip() == 'float':\n",
    "        cond_dict[k.strip()] = float(v.strip())\n",
    "    elif func.strip() == 'str':\n",
    "        cond_dict[k.strip()] = str(v.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'from_month': 6,\n",
       " 'from_year': 2015,\n",
       " 'last_reviewed_ts': True,\n",
       " 'max_num_records': 264,\n",
       " 'to_month': 7,\n",
       " 'to_year': 2016,\n",
       " 'use_improvement_lvl': True,\n",
       " 'which_city': 'chicago'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cond_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN RECORDS FROM THE CSV FILE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2862: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: Metadata table (220364, 18)\n",
      "Data shape  = (220364, 18)\n",
      "Applying conditions: from_year 2015 - to_year 2015\n",
      "Data shape  = (21683, 18)\n",
      "Applying conditions: from_month 6 - to_month 6\n",
      "Data shape  = (11175, 18)\n",
      "Applying conditions: city: chicago\n",
      "Data shape  = (9267, 18)\n",
      "Applying conditions: improvement_lvl: True\n",
      "Data shape land = (4265, 18), house = (4897, 18)\n",
      "Applying conditions: max_num_records: 264\n",
      "Shape: Land Property table (132, 18)\n",
      "Shape: House Property table (132, 18)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'COMPLETE'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = dict(\n",
    "          input_csv_path=input_csv_path,\n",
    "          which_run=which_run,\n",
    "          img_type= image_type,\n",
    "          cond_dict=cond_dict\n",
    ")\n",
    "\n",
    "create_csv_file_for_input(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FETCH AERIAL IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL RECORDS PARSED: IMAGES DONE ======== 190\r"
     ]
    }
   ],
   "source": [
    "# This is basically loading the image from google API,\n",
    "param_dict=dict(\n",
    "      which_run=which_run,\n",
    "      img_type= image_type\n",
    ")\n",
    "\n",
    "dump_aerial(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUMP AERIAL CROPPED IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part uses the polygons to cropp images, augment resize and pad them\n",
    "param_dict=dict(\n",
    "      which_run=which_run,\n",
    "      img_type= image_type\n",
    ")\n",
    "\n",
    "if image_type == 'aerial_cropped':\n",
    "    dump_aerial_cropped(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DUMP OVERLAID IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_dict=dict(\n",
    "      which_run=which_run,\n",
    "      img_type= image_type\n",
    ")\n",
    "\n",
    "if image_type == 'overlaid':\n",
    "    dump_overlaid(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_dict = dict(\n",
    "      which_run=which_run,\n",
    "      img_type=image_type,\n",
    "      is_cvalid_test=False,\n",
    "      batch_size=batch_size,\n",
    "      proportion_cv_data=proportion_cv_data,\n",
    "      proportion_test_data=proportion_test_data\n",
    ")\n",
    "\n",
    "prepare_batches(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST ON NEW IMAGES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_dict = dict(\n",
    "      which_run=which_run,\n",
    "      img_type=image_type,\n",
    "      use_checkpoint_for_run=use_checkpoint_of_run,\n",
    "      use_checkpoint_for_imageType=image_type,\n",
    "      which_net=which_net\n",
    ")\n",
    "\n",
    "test_new(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAKE FINAL PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the data might still have mislabels because its not based on the manually curated test set, \n",
    "# but a random test set from the csv file\n",
    "param_dict = dict(\n",
    "        which_run=which_run,\n",
    "        img_type=image_type,\n",
    "        use_checkpoint_for_run=use_checkpoint_of_run,\n",
    "        use_checkpoint_for_imageType=image_type,\n",
    "        which_net=which_net,\n",
    "        use_checkpoint_for_prediction='all',\n",
    "        classification_threshold=prediction_threshold\n",
    ")\n",
    "\n",
    "predictions(params=param_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMOVE BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = dict(\n",
    "        which_run=which_run,\n",
    "        img_type=image_type\n",
    ")\n",
    "\n",
    "remove_batches(params=param_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Thank you!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT the RUN NAME: Options : (\"A new run name\" or \"Any Previous Run Name\"\n",
      " WHICH_RUN = new_test\n",
      "INPUT: Image-type OPTIONS: (assessor, assessor_code, aerial, overlayed, aerial_cropped, streetside and ensemble \n",
      " IMAGE_TYPE = aerial_cropped\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import logging\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import os\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import numpy as np\n",
    "from config import pathDict\n",
    "from conv_net.train import Train\n",
    "from conv_net.test import Test\n",
    "from data_transformation.data_prep import get_intersecting_images_pin, DumpBatches\n",
    "from plot import Plot\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "which_net = 'resnet'\n",
    "batch_prepare = True\n",
    "train = True\n",
    "test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from clean_directories import clean\n",
    "# clean(dict(overlayed='summary,batch'),which_vendor='google', which_model='resnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARE/DUMP BATCHES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937 937\n",
      "1874 1874 1874 1874======== 13\n",
      "--------------- 89.04272866249084 seconds ------------------\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "max_batches = None\n",
    "\n",
    "if batch_prepare:\n",
    "    start_time = time.time()\n",
    "    \n",
    "    cmn_land_pins, cmn_house_pins = get_intersecting_images_pin(is_assessor=False, is_aerial=False,\n",
    "                                                                is_streetside=False, is_overlayed=False,\n",
    "                                                                is_aerial_cropped=True, equal_proportion=True)\n",
    "    print(len(cmn_land_pins), len(cmn_house_pins))\n",
    "    \n",
    "    tr_batch_size = 128\n",
    "    ts_batch_size = (len(cmn_land_pins) + len(cmn_house_pins)) // 10\n",
    "    cv_batch_size = (len(cmn_land_pins) + len(cmn_house_pins)) // 10\n",
    "    \n",
    "    params = dict(\n",
    "            image_type='aerial_cropped',\n",
    "            img_in_shape=[400, 400, 3],\n",
    "            img_out_shape=[224, 224, 3],\n",
    "            img_resize_shape=[128, 128, 3],\n",
    "            img_crop_shape=[128, 128, 3],\n",
    "            tr_batch_size = tr_batch_size,\n",
    "            cv_batch_size = cv_batch_size,\n",
    "            ts_batch_size = ts_batch_size,\n",
    "            enable_rotation=True,\n",
    "            shuffle_seed=881,\n",
    "            get_stats=True,\n",
    "            max_batches=max_batches)\n",
    "    \n",
    "    obj_cb = DumpBatches(params)\n",
    "    obj_cb.dumpStratifiedBatches_balanced_class(cmn_land_pins, cmn_house_pins, is_cvalid_test=False)\n",
    "\n",
    "print ('--------------- %s seconds ------------------'%(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST MODEL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Graphs: RESNET\n",
      "Learning Rate: Initial:  0.0005\n",
      "Batch path C:\\Users\\newline\\Documents\\ImageClassification\\data\\batch_data\\new_test\\aerial_cropped, batch_names: ['train_0', 'train_1', 'train_10', 'train_11', 'train_12', 'train_13', 'train_2', 'train_3', 'train_4', 'train_5', 'train_6', 'train_7', 'train_8', 'train_9']\n",
      "Test Graphs: RESNET\n",
      "Learning Rate: Initial:  0.0005\n",
      "Batch path C:\\Users\\newline\\Documents\\ImageClassification\\data\\batch_data\\new_test\\aerial_cropped, batch_names: ['train_0', 'train_1', 'train_10', 'train_11', 'train_12', 'train_13', 'train_2', 'train_3', 'train_4', 'train_5', 'train_6', 'train_7', 'train_8', 'train_9']\n",
      "Test Graphs: RESNET\n",
      "Learning Rate: Initial:  0.0005\n",
      "Batch path C:\\Users\\newline\\Documents\\ImageClassification\\data\\batch_data\\new_test\\aerial_cropped, batch_names: ['train_0', 'train_1', 'train_10', 'train_11', 'train_12', 'train_13', 'train_2', 'train_3', 'train_4', 'train_5', 'train_6', 'train_7', 'train_8', 'train_9']\n",
      "Test Graphs: RESNET\n",
      "Learning Rate: Initial:  0.0005\n",
      "Batch path C:\\Users\\newline\\Documents\\ImageClassification\\data\\batch_data\\new_test\\aerial_cropped, batch_names: ['train_0', 'train_1', 'train_10', 'train_11', 'train_12', 'train_13', 'train_2', 'train_3', 'train_4', 'train_5', 'train_6', 'train_7', 'train_8', 'train_9']\n",
      "Test Graphs: RESNET\n",
      "Learning Rate: Initial:  0.0005\n",
      "Batch path C:\\Users\\newline\\Documents\\ImageClassification\\data\\batch_data\\new_test\\aerial_cropped, batch_names: ['train_0', 'train_1', 'train_10', 'train_11', 'train_12', 'train_13', 'train_2', 'train_3', 'train_4', 'train_5', 'train_6', 'train_7', 'train_8', 'train_9']\n"
     ]
    }
   ],
   "source": [
    "which_data = 'test'\n",
    "tsoj = Test(params=dict(pprocessor_inp_img_shape=[224,224,3],\n",
    "                        pprocessor_inp_crop_shape=[],\n",
    "                        model_inp_img_shape=[224, 224, 3]),\n",
    "                    device_type = 'gpu',\n",
    "                    which_net='resnet')\n",
    "fnl_tst_metric_stack = tsoj.run(use_checkpoint_for_run='sam_new',\n",
    "                                use_checkpoint_for_imageType='aerial_cropped',\n",
    "                                optional_batch_name=None,\n",
    "                                which_checkpoint='all',\n",
    "                                which_data=which_data,\n",
    "                                dump_stats=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>test_batch</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_precsion</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>epoch_15_batch_70</td>\n",
       "      <td>train_0</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>epoch_15_batch_70</td>\n",
       "      <td>train_1</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>epoch_15_batch_70</td>\n",
       "      <td>train_10</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>epoch_15_batch_70</td>\n",
       "      <td>train_11</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>epoch_15_batch_70</td>\n",
       "      <td>train_12</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          checkpoint test_batch  test_loss  test_acc  test_precsion  \\\n",
       "0  epoch_15_batch_70    train_0      0.103     0.961          0.968   \n",
       "1  epoch_15_batch_70    train_1      0.228     0.914          0.908   \n",
       "2  epoch_15_batch_70   train_10      0.136     0.953          0.968   \n",
       "3  epoch_15_batch_70   train_11      0.151     0.953          0.939   \n",
       "4  epoch_15_batch_70   train_12      0.242     0.906          0.906   \n",
       "\n",
       "   test_recall  \n",
       "0        0.953  \n",
       "1        0.922  \n",
       "2        0.938  \n",
       "3        0.969  \n",
       "4        0.906  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_outcomes_path = os.path.join(pathDict['statistics_path'], 'prediction_stats', 'test_pred_outcomes.csv')\n",
    "prediction_metrics_path = os.path.join(pathDict['statistics_path'], 'prediction_stats', 'test_pred_metrics.csv')\n",
    "prediction_outcomes = pd.read_csv(prediction_outcomes_path)\n",
    "prediction_metrics = pd.read_csv(prediction_metrics_path)\n",
    "prediction_metrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['epoch_15_batch_70', 'epoch_16_batch_59', 'epoch_16_batch_69',\n",
       "       'epoch_16_batch_70', 'epoch_17_batch_59'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(prediction_metrics[\"checkpoint\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932764140875 0.949058693245 0.91462113127 0.932764140875\n"
     ]
    }
   ],
   "source": [
    "from conv_net.utils import Score\n",
    "predictions = prediction_outcomes[prediction_outcomes['checkpoint'] == 'epoch_17_batch_59']\n",
    "\n",
    "accuracy = Score().accuracy(y_true=predictions[\"true_label\"], y_pred=predictions[\"pred_label\"])\n",
    "\n",
    "precision = Score().precision(y_true=predictions[\"true_label\"], y_pred=predictions[\"pred_label\"], reverse=True)\n",
    "\n",
    "recall = Score().recall(y_true=predictions[\"true_label\"], y_pred=predictions[\"pred_label\"], reverse=True)\n",
    "\n",
    "auc = Score().auc(y_true=predictions[\"true_label\"], y_pred=predictions[\"pred_label\"])\n",
    "\n",
    "print (accuracy, precision, recall, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Reordering is not turned on, and the x array is not increasing: [ 0.  0.  0. ...,  1.  1.  1.]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8a66bf921308>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPlot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mPlot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvizualize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"true_label\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"pred_label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"true_label\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolY\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"pred_label\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mviz_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"roc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"title\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"ROC Curve\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\ImageClassification\\image_classification\\plot.py\u001b[0m in \u001b[0;36mvizualize\u001b[1;34m(self, data, colX, colY, label_col, viz_type, params, multiplot)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mviz_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'roc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
      "\u001b[1;32m~\\Documents\\ImageClassification\\image_classification\\plot.py\u001b[0m in \u001b[0;36mroc\u001b[1;34m(self, data, colX, colY, params, params_keys)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolY\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         ax.plot(fpr, tpr, 'b',\n\u001b[1;32m--> 134\u001b[1;33m                 label='AUC = %0.2f' % metrics.auc(np.array(data[colX]), np.array(data[colY])))\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower right'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mauc\u001b[1;34m(x, y, reorder)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                 raise ValueError(\"Reordering is not turned on, and \"\n\u001b[1;32m---> 99\u001b[1;33m                                  \"the x array is not increasing: %s\" % x)\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[0marea\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirection\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrapz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Reordering is not turned on, and the x array is not increasing: [ 0.  0.  0. ...,  1.  1.  1.]"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAHRCAYAAABU26HZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f7ecb8dc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from plot import Plot\n",
    "Plot().vizualize(data=predictions[[\"true_label\", \"pred_label\"]], colX=\"true_label\", colY=\"pred_label\", label_col=None, viz_type=\"roc\", params={\"title\":\"ROC Curve\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "a = metrics.roc_curve(np.array(predictions[\"true_label\"]), np.array(predictions[\"pred_label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.        ,  0.08537887,  1.        ]),\n",
       " array([ 0.        ,  0.95090715,  1.        ]),\n",
       " array([2, 1, 0], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.95090715,  1.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikitplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-767c6b5dc3bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscikitplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mskplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikitplot'"
     ]
    }
   ],
   "source": [
    "import scikitplot as skplt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
